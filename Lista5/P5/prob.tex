\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage[svgnames]{xcolor}


\lstset{language=R,
    basicstyle=\small\ttfamily,
    stringstyle=\color{DarkGreen},
    otherkeywords={0,1,2,3,4,5,6,7,8,9},
    morekeywords={TRUE,FALSE},
    deletekeywords={data,frame,length,as,character},
    keywordstyle=\color{blue},
    commentstyle=\color{DarkGreen},
}

\author{Albert Ribes}
\title{\textbf{5. Pràctica amb la xarxa MLP 1 [R]}}

\begin{document}
    \maketitle

    Aquesta és una tasca usada com a benchmark en la literatura. Definim
    $f:
    [-1, 1]^2
    \longmapsto
    \mathbb{R} $
    com:
    $f(x_1, x_2) =
    4\sin(\pi x_1) +
    2\cos(\pi x_2 ) +
    \epsilon$
    on
    $\epsilon \sim \mathcal{N}(0, 0.5^2)$
    és soroll normal amb mitjana zero i desviació estàndar
    $1$.

    \begin{enumerate}

        \item Entreneu una xarxa neuronal MLP amb la rutina
        \texttt{nnet\{nnet\}}
        per aprendre la tasca. Heu de fer $4$
        estudis separats, prenent conjunts d'aprenentatge de mida creixent:
            $100$, $200$, $500$ i $1000$, mostrejats
        de manera aleatòria uniformement en
        $[-1, 1]^2$ .
        Caldrà que estimeu la millor arquitectura, cosa que
        podeu fer per \textit{cross-validation}, usant regularització.

        \begin{lstlisting}
        trc <- trainControl (
            method="repeatedcv",
            number=10,
            repeats=5)
        model1 <- train (
            target ~.,
            data = df1,
            linout = TRUE,
            method='nnet',
            metric = "RMSE",
            trControl=trc)
        \end{lstlisting}

        {\bfseries
        Se han generado 4 dataframes con distintos tamaños (\texttt{df1, df2, df3, df4}) y se ha usado \texttt{caret} para encontrar la arquitectura más adecuada para cada uno de ellos. Haciendo $5$ veces 10-fold-cross-validation se han generado 4 modelos distintos, uno para cada dataset de \textit{training}
        }

        \item Reporteu els resultats de predicció dels 4 estudis en un conjunt de test de mida $1024$
        obtingut de
        crear exemples a intervals regulars en
        $[-1, 1]^2$.

        {\bfseries
        Los resultados están en la tabla \ref{res}.

        Es muy curioso que no parece haber mejoría a medida que se incrementa el tamaño de los datos de training. De hecho, los resultados parecen oscilar. Esto puede deberse al factor de azar que hay en la construcción de las redes.

        El proceso de cross-validation ha resultado en las arquitecturas de la tabla \ref{net_data}



        }



\begin{table}[!htbp] \centering
  \caption{Resultados de testing}
  \label{res}
\begin{tabular}{@{\extracolsep{5pt}} cccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
 & RMSE & Rsquared & MAE \\
\hline \\[-1.8ex]
r1.nnet & $0.268$ & $0.993$ & $0.214$ \\
r2.nnet & $0.552$ & $0.970$ & $0.428$ \\
r3.nnet & $0.263$ & $0.993$ & $0.211$ \\
r4.nnet & $1.444$ & $0.797$ & $1.278$ \\
\hline
r1.linear & $2.366$ & $0.491$ & $1.928$ \\
r2.linear & $2.306$ & $0.489$ & $1.885$ \\
r3.linear & $2.300$ & $0.492$ & $1.883$ \\
r4.linear & $2.284$ & $0.492$ & $1.875$ \\
% r1.linear.not.regularized & $2.366$ & $0.491$ & $1.928$ \\
% r2.linear.not.regularized & $2.306$ & $0.489$ & $1.885$ \\
% r3.linear.not.regularized & $2.300$ & $0.492$ & $1.883$ \\
% r4.linear.not.regularized & $2.284$ & $0.492$ & $1.875$ \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}

\begin{table}[!htbp] \centering
\caption{Arquitectura de las redes}
\label{net_data}
\begin{tabular}{@{\extracolsep{5pt}} ccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
& size & decay \\
\hline \\[-1.8ex]
model1.nnet & $5$ & $0$ \\
model2.nnet & $5$ & $0.100$ \\
model3.nnet & $5$ & $0.100$ \\
model4.nnet & $5$ & $0.0001$ \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}

        \item Repetiu els experiments usant regressió lineal amb i sense regularització en els mateixos conjunts
        de dades i compareu els resultats obtinguts amb els de la xarxa MLP; noteu que podeu usar
        simplement la rutina
        \texttt{nnet}
        amb
        \texttt{size=0}.

        {\bfseries

        Los resultados están en la tabla \ref{res}.

        En el caso de modelos lineales con regularización sí que se mejoran a medida que los datos de training se incrementan. Con esto se ve que los modelos lineales son más estables que las redes neuronales.

        De todos modos, las redes neuronales siempre tienen unos resultados mejores que los modelos lineales. Esto puede ser un indicador de que el modelo lineal no tiene suficiente potencia para representar estos datos. De hecho, los modelos que se han creado no generan nuevos datos de entrada, y no tiene suficiente flecibilidad para representar las funciones de seno y coseno.


        No he sido capaz de hacer un modelo lineal con R que no regularice.
        }
    \end{enumerate}

\end{document}
